{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear and Logistic regression with pandas\n",
    "\n",
    "I conclude from this experiment that unless you absolutely need to, because of data size or speed, you're better off doing this in R, which is made for it.\n",
    "\n",
    "## Ordinary Least Squares using pandas\n",
    "\n",
    "You have to have a library called 'statsmodels' installed in order to use the linear regression tools in pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.stats.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get R-like output from a (synthetic) linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-------------------------Summary of Regression Analysis-------------------------\n",
       "\n",
       "Formula: Y ~ <A> + <B> + <intercept>\n",
       "\n",
       "Number of Observations:         5\n",
       "Number of Degrees of Freedom:   3\n",
       "\n",
       "R-squared:         0.9996\n",
       "Adj R-squared:     0.9992\n",
       "\n",
       "Rmse:              0.0661\n",
       "\n",
       "F-stat (2, 2):  2551.1438, p-value:     0.0004\n",
       "\n",
       "Degrees of Freedom: model 2, resid 2\n",
       "\n",
       "-----------------------Summary of Estimated Coefficients------------------------\n",
       "      Variable       Coef    Std Err     t-stat    p-value    CI 2.5%   CI 97.5%\n",
       "--------------------------------------------------------------------------------\n",
       "             A     2.0359     0.0293      69.55     0.0002     1.9785     2.0932\n",
       "             B    -1.0844     0.0293     -37.04     0.0007    -1.1418    -1.0270\n",
       "     intercept     7.0954     0.0742      95.66     0.0001     6.9500     7.2408\n",
       "---------------------------------End of Summary---------------------------------"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use array to create these and not ndarray:\n",
    "# with ndarray, that list is interpreted as the dimensions\n",
    "lista = np.array([1,2,3,4,5])\n",
    "listb = np.array([2,3,1,4,5])\n",
    "\n",
    "# note that the dependent variable listc is created with known coefficients.\n",
    "# the generating formula is: C = 2A - B + 7 + noise.\n",
    "listc = 2*lista + -1*listb + np.full([5], 7.0) + np.random.randn(5)*.1\n",
    "\n",
    "df = pd.DataFrame({\"A\": lista, \n",
    "                   \"B\": listb, \n",
    "                   \"C\": listc})\n",
    "\n",
    "result = ols(y=df['C'], x=df[['A','B']])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The numpy 'full' function is like the 'repl' function in R (for array creation)\n",
    "# a.shape in numpy is like dim(a) in R.\n",
    "np.full([5],7.0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get R-like output from logistic regression.\n",
    "\n",
    "This is taken from: http://blog.yhat.com/posts/logistic-regression-and-python.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'admit', u'gre', u'gpa', u'rank'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "df2 = pd.read_csv(\"gradschool.csv\")\n",
    "print df2.columns # shows headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>780</td>\n",
       "      <td>3.87</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>2.56</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>2.82</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>680</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    admit  gre   gpa  prestige\n",
       "0       0  380  3.61         3\n",
       "1       1  660  3.67         3\n",
       "2       1  800  4.00         1\n",
       "3       1  640  3.19         4\n",
       "4       0  520  2.93         4\n",
       "5       1  760  3.00         2\n",
       "6       1  560  2.98         1\n",
       "7       0  400  3.08         2\n",
       "8       1  540  3.39         3\n",
       "9       0  700  3.92         2\n",
       "10      0  800  4.00         4\n",
       "11      0  440  3.22         1\n",
       "12      1  760  4.00         1\n",
       "13      0  700  3.08         2\n",
       "14      1  700  4.00         1\n",
       "15      0  480  3.44         3\n",
       "16      0  780  3.87         4\n",
       "17      0  360  2.56         3\n",
       "18      0  800  3.75         2\n",
       "19      1  540  3.81         1\n",
       "20      0  500  3.17         3\n",
       "21      1  660  3.63         2\n",
       "22      0  600  2.82         4\n",
       "23      0  680  3.19         4\n",
       "24      1  760  3.35         2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a few records. Note the admit variable is binary.\n",
    "# rank 1 institutions have the highest prestige.\n",
    "df2.head(25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'admit', u'gre', u'gpa', u'prestige'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# rename the 'rank' column because there is also a DataFrame method called 'rank'\n",
    "df2.columns = [\"admit\", \"gre\", \"gpa\", \"prestige\"]\n",
    "print df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>587.700000</td>\n",
       "      <td>3.389900</td>\n",
       "      <td>2.48500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.516536</td>\n",
       "      <td>0.380567</td>\n",
       "      <td>0.94446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.395000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre         gpa   prestige\n",
       "count  400.000000  400.000000  400.000000  400.00000\n",
       "mean     0.317500  587.700000    3.389900    2.48500\n",
       "std      0.466087  115.516536    0.380567    0.94446\n",
       "min      0.000000  220.000000    2.260000    1.00000\n",
       "25%      0.000000  520.000000    3.130000    2.00000\n",
       "50%      0.000000  580.000000    3.395000    2.00000\n",
       "75%      1.000000  660.000000    3.670000    3.00000\n",
       "max      1.000000  800.000000    4.000000    4.00000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prestige</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>97</td>\n",
       "      <td>93</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prestige   1   2   3   4\n",
       "admit                   \n",
       "0         28  97  93  55\n",
       "1         33  54  28  12"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# You can look at frequency tables to see a view of what is going on.\n",
    "# The frequency table below compares prestige and whether or not someone was admitted.\n",
    "# prestige == 1 is the highest, apparently. \n",
    "# crosstab is a function that lets you do multidimensional frequency tables. \n",
    "# you are marginalizing counts over the other independent variables. \n",
    "# Notice below that it looks easier to get into the high-prestige universities than the other ones.\n",
    "# that can't be right!\n",
    "pd.crosstab(df2['admit'], df2['prestige'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gpa</th>\n",
       "      <th>2.26</th>\n",
       "      <th>2.42</th>\n",
       "      <th>2.48</th>\n",
       "      <th>2.52</th>\n",
       "      <th>2.55</th>\n",
       "      <th>2.56</th>\n",
       "      <th>2.62</th>\n",
       "      <th>2.63</th>\n",
       "      <th>2.65</th>\n",
       "      <th>2.67</th>\n",
       "      <th>...</th>\n",
       "      <th>3.9</th>\n",
       "      <th>3.91</th>\n",
       "      <th>3.92</th>\n",
       "      <th>3.93</th>\n",
       "      <th>3.94</th>\n",
       "      <th>3.95</th>\n",
       "      <th>3.97</th>\n",
       "      <th>3.98</th>\n",
       "      <th>3.99</th>\n",
       "      <th>4.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "gpa    2.26  2.42  2.48  2.52  2.55  2.56  2.62  2.63  2.65  2.67  ...   3.90  \\\n",
       "admit                                                              ...          \n",
       "0         1     1     1     1     1     1     1     1     0     1  ...      2   \n",
       "1         0     1     0     0     0     0     1     0     1     1  ...      1   \n",
       "\n",
       "gpa    3.91  3.92  3.93  3.94  3.95  3.97  3.98  3.99  4.00  \n",
       "admit                                                        \n",
       "0         1     2     1     4     1     1     0     2    15  \n",
       "1         0     0     0     1     4     0     1     1    13  \n",
       "\n",
       "[2 rows x 132 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is not what you want. You want to bin the gpa values before you do a frequency analysis.\n",
    "pd.crosstab(df2['admit'], df2['gpa'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the cut function creates bins. In this case there are 6 equal-width bins spanning the range of gpas in the data set. \n",
    "# \n",
    "df2['gpa_bin']=pd.cut(df2['gpa'], bins = 6, labels = False, precision = 1, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "      <th>gpa_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  prestige  gpa_bin\n",
       "0      0  380  3.61         3        4\n",
       "1      1  660  3.67         3        4\n",
       "2      1  800  4.00         1        5\n",
       "3      1  640  3.19         4        3\n",
       "4      0  520  2.93         4        2"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gpa_bin</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>57</td>\n",
       "      <td>81</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "gpa_bin  0   1   2   3   4   5\n",
       "admit                         \n",
       "0        5  20  57  81  57  53\n",
       "1        1   6  15  24  45  36"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you can call crosstab!\n",
    "pd.crosstab(df2['admit'], df2['gpa_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "      <th>gpa_bin</th>\n",
       "      <th>gre_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  prestige  gpa_bin  gre_bin\n",
       "0      0  380  3.61         3        4        2\n",
       "1      1  660  3.67         3        4        7\n",
       "2      1  800  4.00         1        5        9\n",
       "3      1  640  3.19         4        3        7\n",
       "4      0  520  2.93         4        2        5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do the same with gres. Make 10 bins this time.\n",
    "df2['gre_bin']=pd.cut(df2['gre'], bins = 10, labels = False, precision = 1, include_lowest=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gre_bin</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "gre_bin  0  1   2   3   4   5   6   7   8   9\n",
       "admit                                        \n",
       "0        1  2  15  24  39  50  55  39  32  16\n",
       "1        0  1   1   4  12  25  27  26  12  19"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df2['admit'], df2['gre_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  prestige\n",
       "0      0  380  3.61         3\n",
       "1      1  660  3.67         3\n",
       "2      1  800  4.00         1\n",
       "3      1  640  3.19         4\n",
       "4      0  520  2.93         4"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ha! I remembered to use the loc function!\n",
    "df3 = df2.loc[:,['admit', 'gre', 'gpa', 'prestige']]\n",
    "\n",
    "# this gives me the original dataframe back\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5685f1910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# easy histogram function. Note up front that about 1 out of 3 applicants were admitted.\n",
    "df3.hist()\n",
    "pl.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2</th>\n",
       "      <th>prestige_3</th>\n",
       "      <th>prestige_4</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  prestige_2  prestige_3  prestige_4  intercept\n",
       "0      0  380  3.61           0           1           0          1\n",
       "1      1  660  3.67           0           1           0          1\n",
       "2      1  800  4.00           0           0           0          1\n",
       "3      1  640  3.19           0           0           1          1\n",
       "4      0  520  2.93           0           0           1          1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now you can convert the categorical variables to dummies.\n",
    "dummy_prestige = pd.get_dummies(df2['prestige'], prefix = \"prestige\")\n",
    "\n",
    "# note how the dummy variables relate to the original variable\n",
    "df2[[\"prestige\"]].join(dummy_prestige).head()\n",
    "\n",
    "# get rid of the prestige column, and one of the dummies, \n",
    "# to have an independent set of dummy representatives for the original prestige variable.\n",
    "df4 = df3[[\"admit\", \"gre\", \"gpa\"]].join(dummy_prestige.iloc[:, 1:4])\n",
    "\n",
    "# manually add a column of 1s for an intercept. This is different from R, entirely.\n",
    "df4[\"intercept\"] = 1.0\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing the logistic regression from this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'gre', u'gpa', u'prestige_2', u'prestige_3', u'prestige_4',\n",
      "       u'intercept'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "indep_cols = df4.columns[1:]\n",
    "print indep_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of the logistic regression\n",
    "\n",
    "the summary() function on statsmodels results gives nice output. \n",
    "\n",
    "- the GRE variable does not look especially significant. Can we drop it?\n",
    "- gpa is significant and positive\n",
    "- as the prestige of the university drops, it appears admittance is less likely. This seems paradoxical. Is something confounding it?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573147\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  admit   No. Observations:                  400\n",
      "Model:                          Logit   Df Residuals:                      394\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Thu, 03 Mar 2016   Pseudo R-squ.:                 0.08292\n",
      "Time:                        20:01:22   Log-Likelihood:                -229.26\n",
      "converged:                       True   LL-Null:                       -249.99\n",
      "                                        LLR p-value:                 7.578e-08\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "gre            0.0023      0.001      2.070      0.038         0.000     0.004\n",
      "gpa            0.8040      0.332      2.423      0.015         0.154     1.454\n",
      "prestige_2    -0.6754      0.316     -2.134      0.033        -1.296    -0.055\n",
      "prestige_3    -1.3402      0.345     -3.881      0.000        -2.017    -0.663\n",
      "prestige_4    -1.5515      0.418     -3.713      0.000        -2.370    -0.733\n",
      "intercept     -3.9900      1.140     -3.500      0.000        -6.224    -1.756\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "logit = sm.Logit(df4[\"admit\"], df4[indep_cols])\n",
    "result = logit.fit()\n",
    "print result.summary() # this is a statsmodels function -- it has nice summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation (from http://stats.stackexchange.com/questions/108995/interpreting-residual-and-null-deviance-in-glm-r)\n",
    "\n",
    "    Let LL = loglikelihood\n",
    "\n",
    "    Here is a quick summary of what you see from the summary(glm.fit) output,\n",
    "\n",
    "    Null Deviance = 2(LL(Saturated Model) - LL(Null Model)) on df = df_Sat - df_Null\n",
    "\n",
    "    Residual Deviance = 2(LL(Saturated Model) - LL(Proposed Model)) df = df_Sat - df_Res\n",
    "\n",
    "    The Saturated Model is a model that assumes each data point has its own parameters (which means you have n parameters to estimate.)\n",
    "\n",
    "    The Null Model assumes the exact \"opposite\", in that is assumes one parameter for all of the data points, which means you only estimate 1 parameter.\n",
    "\n",
    "    The Proposed Model assumes you can explain your data points with p parameters + an intercept term, so you have p+1 parameters.\n",
    "\n",
    "    If your Null Deviance is really small, it means that the Null Model explains the data pretty well. Likewise with your Residual Deviance.\n",
    "\n",
    "    What does really small mean? If your model is \"good\" then your Deviance is approx Chi^2 with (df_sat - df_model) degrees of freedom.\n",
    "\n",
    "    If you want to compare you Null model with your Proposed model, then you can look at\n",
    "\n",
    "    (Null Deviance - Residual Deviance) approx Chi^2 with df Proposed - df Null = (n-(p+1))-(n-1)=p\n",
    "\n",
    "    Are the results you gave directly from R? They seem a little bit odd, because generally you should see that the degrees of freedom reported on the Null are always higher than the degrees of freedom reported on the Residual. That is because again, \n",
    "\n",
    "        Null Deviance df = Saturated df - Null df = n-1 \n",
    "        Residual Deviance df = Saturated df - Proposed df = n-(p+1)\n",
    "    \n",
    "    \n",
    "### So, pandas output does not give residual deviance, it gives Null LL and model LL. \n",
    "\n",
    "My Notes on this output: \n",
    "\n",
    "The log-likelihood ratio (LLR) test that the pandas output is describing is a test comparing the null (intercept-only) model to the proposed model. i confirmed this by calculating the statistic offline, and checking its p-value, which is exactly the same as the reported one.\n",
    "\n",
    "- why do we want to test the proposed vs. the null model? The question we really want answered is this: is this proposed model any better than the intercept-only model? \n",
    "\n",
    "We really aren't asking whether it's a good fit to the data; we are just asking whether it's a better fit than the intercept-only model. In order to do that, we mangle our assumptions a bit so that we meet the assumptions of this test: we assume (behind the scenes) that the proposed model is good, and then we ask whether the null model is equally good. A small p-value suggests that it isn't, so the proposed model, whether it fits or not, is at least better than nothing. \n",
    "\n",
    "I guess the point is to see whether our model is any better than the null model, and this test suggests that it is.\n",
    "\n",
    "The basis of the test is this: the null hypothesis is that the smaller model (the intercept-only model) being tested is valid, and the alternative is that the larger model (the proposed model) is valid. The statistic is -2 (LL(smaller) - LL(larger)), and in the limit this is distributed as chisq with df = difference in number of model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.5747556782523873e-08"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "aa = 2*(-229.26 - (-249.99))\n",
    "1 - chi2.cdf(aa, df=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
